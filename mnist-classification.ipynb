{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ramsesmdlc/mnist-linear-classification?scriptVersionId=139638095\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# __0. Libraries__","metadata":{}},{"cell_type":"code","source":"#Import Libraries \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport matplotlib as mpl # data visualization\nimport matplotlib.pyplot as plt # data visualization (\"pyplot module\", a.k.a. \"plt\")\n\n    #Each \"pyplot\" function makes some change to a figure: e.g., creates a figure, creates a...\n    #...plotting area in a figure, plots some lines in a plotting area, decorates the plot with...\n    #...labels, etc. The various plots we can utilize using Pyplot are Line Plot, Histogram, Scatter,...\n    #...3D Plot, Image, Contour, and Polar.\n\nfrom sklearn.linear_model import SGDClassifier # Machine Learning (Linear Classification)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T16:33:33.229976Z","iopub.execute_input":"2023-08-11T16:33:33.230361Z","iopub.status.idle":"2023-08-11T16:33:33.522032Z","shell.execute_reply.started":"2023-08-11T16:33:33.230331Z","shell.execute_reply":"2023-08-11T16:33:33.520579Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# __1. Important__\n\nType of machine learning system to build:\n\n1. Supervised Learning: __Classification__\n2. Batch Learning (also called \"offline learning\")\n3. Model-based learning\n\nGoal:\n1. __It is to take an image of a handwritten single digit, and determine what that digit is.__\n\n2. __Metric__: This competition is evaluated on the categorization accuracy of your predictions (the percentage of images you get correct).","metadata":{}},{"cell_type":"markdown","source":"# __2. Loading the Data - Training Dataset__","metadata":{}},{"cell_type":"code","source":"training_data = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-11T16:15:46.81116Z","iopub.execute_input":"2023-08-11T16:15:46.812035Z","iopub.status.idle":"2023-08-11T16:15:49.613561Z","shell.execute_reply.started":"2023-08-11T16:15:46.811982Z","shell.execute_reply":"2023-08-11T16:15:49.612583Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## __2.1. General Information__","metadata":{}},{"cell_type":"markdown","source":"1. The data file contain __gray-scale images__ of hand-drawn digits, from 0 through 9.\n\n2. Each image is __28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.__\n\n> __Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel__, with higher numbers meaning darker. \n\n> This pixel-value is an integer between 0 and 255, inclusive.\n\n> __Each pixel is a feature__.\n\n3. The __training data set, has 785 columns__. The first column, called \"label\", is the digit that was drawn by the user. The __rest of the columns contain the pixel-values of the associated image__.\n\n4. __Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive__. \n\n> For example: To locate this pixel (\"pixel31\") on the image, \"pixel31\" indicates the pixel is in the fourth column from the left, and the second row from the top.","metadata":{}},{"cell_type":"markdown","source":"# __3. Exploratory Data Analysis (EDA) - Training Dataset__","metadata":{}},{"cell_type":"code","source":"def EDA(training_data):  \n  # Print the \"shape\" of the dataframe\n  print(\"\\n\" +'\\033[1m','\\033[94m',\"Shape of the dataframe - some metric variables:\",'\\033[0m', training_data.shape, \"\\n\")\n    \n  # Print the \"keys\" of the dataframe\n  print('\\033[1m','\\033[94m',\"Keys of the dataframe - some metric variables:\",'\\033[0m', \"\\n\")\n  print(training_data.keys())  \n    \n  # Print the \"head\" of the dataframe\n  print('\\033[1m','\\033[94m',\"Head of the dataframe - some metric variables:\",'\\033[0m', \"\\n\")\n  print(training_data.head())\n  \n  # Print the \"general information\" of the dataframe\n  print(\"\\n\", '\\033[1m','\\033[94m',\"Information of the dataframe - some metric variables:\",'\\033[0m', \"\\n\")\n  training_data.info()\n \n  # Print the \"number and percentage\" of missing values per column\" of some metric variables of the dataframe\n  print(\"\\n\" +'\\033[1m','\\033[94m', \"Number and percentage of missing values per column of some metric variables of the dataframe:\", '\\033[0m' + \"\\n\")\n  missing = training_data.isnull().sum()\n  percent = missing / training_data.shape[0] * 100\n  print(pd.concat([missing, percent], axis=1, keys=[\"Missing\", \"Percent\"]))\n    \n# Call the function\nEDA(training_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T16:15:49.615438Z","iopub.execute_input":"2023-08-11T16:15:49.615833Z","iopub.status.idle":"2023-08-11T16:15:49.716191Z","shell.execute_reply.started":"2023-08-11T16:15:49.615805Z","shell.execute_reply":"2023-08-11T16:15:49.714625Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n\u001b[1m \u001b[94m Shape of the dataframe - some metric variables: \u001b[0m (42000, 785) \n\n\u001b[1m \u001b[94m Keys of the dataframe - some metric variables: \u001b[0m \n\nIndex(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n       'pixel6', 'pixel7', 'pixel8',\n       ...\n       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n      dtype='object', length=785)\n\u001b[1m \u001b[94m Head of the dataframe - some metric variables: \u001b[0m \n\n   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]\n\n \u001b[1m \u001b[94m Information of the dataframe - some metric variables: \u001b[0m \n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 42000 entries, 0 to 41999\nColumns: 785 entries, label to pixel783\ndtypes: int64(785)\nmemory usage: 251.5 MB\n\n\u001b[1m \u001b[94m Number and percentage of missing values per column of some metric variables of the dataframe: \u001b[0m\n\n          Missing  Percent\nlabel           0      0.0\npixel0          0      0.0\npixel1          0      0.0\npixel2          0      0.0\npixel3          0      0.0\n...           ...      ...\npixel779        0      0.0\npixel780        0      0.0\npixel781        0      0.0\npixel782        0      0.0\npixel783        0      0.0\n\n[785 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## __3.1. Adjusting the Training Dataset__\n\n1. If we want to see the data (as an image), we should consider what is described in the section \"2.1. General Information\" (i.e. the pixel's value of the image of every number is entirely displayed in one single row composed by 784 values); therefore, it is necessary rescaling the data (i.e. rescale each row from a shape of {1 x 784} pixels to {28 x 28} pixels.\n\n2. Before applying the \"reshape\" function, we need to transform our dataset from \"Pandas dataframe\" to a \"Numpy Array\", because the \"Numpy Array\" has the function \"reshape\" available.","metadata":{}},{"cell_type":"code","source":"#Separating the Y and X values (i.e. dependent and independent variables)\nY_training, X_training = training_data[\"label\"],training_data.iloc[:, 1:785] \n\n#Printing the \"shape\" of the dependent and independent variables (separately)\nprint(Y_training.shape)\nprint(X_training.shape)\n\n#Printing the \"type\" of the dependent and independent variables (separately)\nprint(type(Y_training))\nprint(type(X_training))\n\n#Transforming the \"independent variables\" (from Pandas Dataframe to Numpy Array)\narray_X = X_training.to_numpy()\nprint(array_X)\n\n#Printing the \"shape\" of the independent variables (as a Numpy Array)\nprint(array_X.shape) ","metadata":{"execution":{"iopub.status.busy":"2023-08-11T16:15:49.717779Z","iopub.execute_input":"2023-08-11T16:15:49.718166Z","iopub.status.idle":"2023-08-11T16:15:49.729873Z","shell.execute_reply.started":"2023-08-11T16:15:49.718129Z","shell.execute_reply":"2023-08-11T16:15:49.727942Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(42000,)\n(42000, 784)\n<class 'pandas.core.series.Series'>\n<class 'pandas.core.frame.DataFrame'>\n[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n(42000, 784)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Printing the image of a number (just to check!)\n\n#Digit of row N°5, counting from 0,1,2,3,4 (without rescaling)\n    #If we see the section \"3. Exploratory Data Analysis (EDA) - Training Dataset\", the output should\n    #...be the number zero (0)\ndigitx1 = array_X[4]\nprint(\"\\n\", '\\033[1m','\\033[94m',\"Target Value of the Image:\",'\\033[0m', \"\\n\")\nprint(Y_training[4])\nprint(\"\\n\", '\\033[1m','\\033[94m',\"Value of every pixel of the image (28 x 28 pixels):\",'\\033[0m', \"\\n\")\nprint(digitx1)\n\n#Digit of row N°5 (with rescaling)\ndigitx1_image = digitx1.reshape(28, 28)\n\n#The matplotlibe function \"imshow\":\n    #Display data as an image.\n    #The input may either be actual RGB(A) data, or 2D scalar data, which will be rendered as a...\n    #...pseudocolor image. For displaying a grayscale image set up the colormapping using the...\n    #...parameters cmap='gray', vmin=0, vmax=255.\n    #The number of pixels used to render an image is set by the Axes size and the dpi of the figure.\nprint(\"\\n\", '\\033[1m','\\033[94m',\"Image (28 x 28 pixels):\",'\\033[0m', \"\\n\")\nplt.imshow(digitx1_image,cmap=\"binary\")\nplt.axis(\"off\")\nplt.show ","metadata":{"execution":{"iopub.status.busy":"2023-08-11T16:41:52.50091Z","iopub.execute_input":"2023-08-11T16:41:52.501267Z","iopub.status.idle":"2023-08-11T16:41:52.579769Z","shell.execute_reply.started":"2023-08-11T16:41:52.501239Z","shell.execute_reply":"2023-08-11T16:41:52.578515Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\n \u001b[1m \u001b[94m Target Value of the Image: \u001b[0m \n\n0\n\n \u001b[1m \u001b[94m Value of every pixel of the image (28 x 28 pixels): \u001b[0m \n\n[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   1  25 130 155 254\n 254 254 157  30   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   8 103 253 253 253 253 253 253 253 253 114   2   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0  11 208 253 253 253\n 253 253 253 253 253 253 253 107   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0  31 253 253 253 253 253 253 253 253 253 253 253 215\n 101   3   0   0   0   0   0   0   0   0   0   0   0   0  23 210 253 253\n 253 248 161 222 222 246 253 253 253 253 253  39   0   0   0   0   0   0\n   0   0   0   0   0   0 136 253 253 253 229  77   0   0   0  70 218 253\n 253 253 253 215  91   0   0   0   0   0   0   0   0   0   0   5 214 253\n 253 253 195   0   0   0   0   0 104 224 253 253 253 253 215  29   0   0\n   0   0   0   0   0   0   0 116 253 253 253 247  75   0   0   0   0   0\n   0  26 200 253 253 253 253 216   4   0   0   0   0   0   0   0   0 254\n 253 253 253 195   0   0   0   0   0   0   0   0  26 200 253 253 253 253\n   5   0   0   0   0   0   0   0   0 254 253 253 253  99   0   0   0   0\n   0   0   0   0   0  25 231 253 253 253  36   0   0   0   0   0   0   0\n   0 254 253 253 253  99   0   0   0   0   0   0   0   0   0   0 223 253\n 253 253 129   0   0   0   0   0   0   0   0 254 253 253 253  99   0   0\n   0   0   0   0   0   0   0   0 127 253 253 253 129   0   0   0   0   0\n   0   0   0 254 253 253 253  99   0   0   0   0   0   0   0   0   0   0\n 139 253 253 253  90   0   0   0   0   0   0   0   0 254 253 253 253  99\n   0   0   0   0   0   0   0   0   0  78 248 253 253 253   5   0   0   0\n   0   0   0   0   0 254 253 253 253 216  34   0   0   0   0   0   0   0\n  33 152 253 253 253 107   1   0   0   0   0   0   0   0   0 206 253 253\n 253 253 140   0   0   0   0   0  30 139 234 253 253 253 154   2   0   0\n   0   0   0   0   0   0   0  16 205 253 253 253 250 208 106 106 106 200\n 237 253 253 253 253 209  22   0   0   0   0   0   0   0   0   0   0   0\n  82 253 253 253 253 253 253 253 253 253 253 253 253 253 209  22   0   0\n   0   0   0   0   0   0   0   0   0   0   1  91 253 253 253 253 253 253\n 253 253 253 253 213  90   7   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   1  18 129 208 253 253 253 253 159 129  90   4   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0]\n\n \u001b[1m \u001b[94m Image (28 x 28 pixels): \u001b[0m \n\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<function matplotlib.pyplot.show(close=None, block=None)>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"#Printing the image of a number (just to check!)\n\n#Digit of row N°3, counting from 0,1,2 (without rescaling)\n    #If we see the section \"3. Exploratory Data Analysis (EDA) - Training Dataset\", the output should\n    #...be the number one (1)\ndigitx2 = array_X[2]\nprint(\"\\n\", '\\033[1m','\\033[94m',\"Target Value of the Image:\",'\\033[0m', \"\\n\")\nprint(Y_training[2])\nprint(\"\\n\", '\\033[1m','\\033[94m',\"Value of every pixel of the image (28 x 28 pixels):\",'\\033[0m', \"\\n\")\nprint(digitx2)\n\n#Digit of row N°3 (with rescaling)\ndigitx2_image = digitx2.reshape(28, 28)\n\n#The matplotlibe function \"imshow\":\n    #Display data as an image.\n    #The input may either be actual RGB(A) data, or 2D scalar data, which will be rendered as a...\n    #...pseudocolor image. For displaying a grayscale image set up the colormapping using the...\n    #...parameters cmap='gray', vmin=0, vmax=255.\n    #The number of pixels used to render an image is set by the Axes size and the dpi of the figure.\nprint(\"\\n\", '\\033[1m','\\033[94m',\"Image (28 x 28 pixels):\",'\\033[0m', \"\\n\")\nplt.imshow(digitx2_image,cmap=\"binary\")\nplt.axis(\"off\")\nplt.show ","metadata":{"execution":{"iopub.status.busy":"2023-08-11T16:42:05.840625Z","iopub.execute_input":"2023-08-11T16:42:05.840999Z","iopub.status.idle":"2023-08-11T16:42:05.922459Z","shell.execute_reply.started":"2023-08-11T16:42:05.840966Z","shell.execute_reply":"2023-08-11T16:42:05.92036Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\n \u001b[1m \u001b[94m Target Value of the Image: \u001b[0m \n\n1\n\n \u001b[1m \u001b[94m Value of every pixel of the image (28 x 28 pixels): \u001b[0m \n\n[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3 141\n 139   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   9 254 254   8   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   9 254 254   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   9 254 254 106   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   9 254 254 184   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   9 254 254 184   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   9 254 254 184   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6 185 254 184\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0  89 254 184   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4 146\n 254 184   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   9 254 254 184   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   9 254 254 184   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   9 254 254 184   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   9 254 254 184   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   9 254 254 184   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0 156 254 254 184   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0 185 255 255 184\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0 185 254 254 184   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 185 254\n 254 184   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0  63 254 254  62   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0]\n\n \u001b[1m \u001b[94m Image (28 x 28 pixels): \u001b[0m \n\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<function matplotlib.pyplot.show(close=None, block=None)>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# __4. Training and the Model - Training Dataset__","metadata":{}},{"cell_type":"code","source":"sgd_classifier = SGDClassifier (random_state = 100)\nsgd_classifier.fit(X_training, Y_training)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T16:37:42.364816Z","iopub.execute_input":"2023-08-11T16:37:42.365269Z","iopub.status.idle":"2023-08-11T16:39:03.369587Z","shell.execute_reply.started":"2023-08-11T16:37:42.365234Z","shell.execute_reply":"2023-08-11T16:39:03.368057Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"SGDClassifier(random_state=100)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=100)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"sgd_classifier.predict([X_training(2)])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T16:43:46.871963Z","iopub.execute_input":"2023-08-11T16:43:46.872348Z","iopub.status.idle":"2023-08-11T16:43:46.904406Z","shell.execute_reply.started":"2023-08-11T16:43:46.872317Z","shell.execute_reply":"2023-08-11T16:43:46.902424Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sgd_classifier\u001b[38;5;241m.\u001b[39mpredict([\u001b[43mX_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m])\n","\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"],"ename":"TypeError","evalue":"'DataFrame' object is not callable","output_type":"error"}]},{"cell_type":"markdown","source":"# __<span style=\"color:red\">UNFINISHED NOTEBOOK! - I AM STILL WORKING ON IT!</span>__","metadata":{}}]}